{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A demo for model predictions based on the transfer-learnt model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load essential packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and functions\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "torch.backends.cudnn.benchmark = False\n",
    "from torchsummary import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from dataset import BrainDataset\n",
    "from load_save_checkpoint import load_checkpoint, save_checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "## Whether to train on a gpu\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')\n",
    "\n",
    "## Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "else:\n",
    "    multi_gpu = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['./119833_Motor_1_lh.nii.gz']\n",
    "label_list = [[0,0,0,1,0,0,0]]\n",
    "\n",
    "dataset = BrainDataset(file_list, label_list, is_train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_bestloss = './checkpoint/3dconv-transfer_checkpoint_bestloss_v6.pth'\n",
    "model, optimizer = load_checkpoint(checkpoint_path_bestloss, train_on_gpu, multi_gpu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a summary of the model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    if multi_gpu:\n",
    "        summary(\n",
    "            model.module,\n",
    "            input_size=(27, 75, 93, 81),   # the input_size needs to be updated!!!\n",
    "            batch_size=batch_size,\n",
    "            device='cuda')\n",
    "    else:\n",
    "        summary(\n",
    "            model, input_size=(27, 75, 93, 81), batch_size=batch_size, device='cuda')  # the input_size needs to be updated!!!\n",
    "else:\n",
    "    summary(\n",
    "        model, input_size=(27, 75, 93, 81), batch_size=batch_size, device='cpu')  # the input_size needs to be updated!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a prediction from an input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs, label = dataset[0]\n",
    "    if train_on_gpu:\n",
    "        pred_prob = F.softmax(model(torch.FloatTensor(inputs).unsqueeze(0).to(device = 'cuda')))\n",
    "    else:\n",
    "        pred_prob = F.softmax(model(torch.FloatTensor(inputs).unsqueeze(0).to(device = 'cpu')))\n",
    "pred_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdshaps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
